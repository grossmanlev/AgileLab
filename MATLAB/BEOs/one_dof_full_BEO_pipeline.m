function fineReconstructedObjects = one_dof_full_BEO_pipeline(partialFlag, poseEstimateFlag, lazyMode)
    % some hardcoded stuff for now, this chunk may need to be edited
    % assumes current matlab folder is the loation of this file
    %
    % this function runs the fill 1DOF pose estimate - classify - complete
    % pipeline using the BEO technique on the ModelNet10 dataset
    %
    % partialFlag can be either 'full' or 'partial', if 'partial', top-down single views are used
    % otherwise full object models are used (during testing)
    %
    % poseEstimateFlag can be true or false, if false does not perform pose
    % estimation (uses true pose), if true performs 1-dof pose estimation about
    % z axis
    %
    % lazyMode can be true or false, if true, tries to used precomputed training
    % data if it is found
    %
    % fineReconstructedObjects are the completions resulting from the pipeline
    %
    % example: completedObjects = one_dof_full_BEO_pipeline('partial', true, false);
    %
    % Ignore the fact that some variables have 'GPU' in the name. An earlier
    % version of this had GPU accelleration but since adding ridge regression
    % that was reverted
    %
    % version 3.1
    % Ben Burchfiel, 2017
    % tested on MATLAB 2016b
    % bcburch@cs.duke.edu
    
    vobjectSize = 30; % NOTE: changed from 30
    step = 1;
    
    % paths for loading data
    pre = [pwd, '/VBPCA/'];
    post = ['_auto_basis_size_', num2str(vobjectSize), '_vobject.mat'];
    % class numbers are in this order, 1 being bathtub and 10 being toilet
    names = {'bottle'};
    pathPrefix = [pwd, '/Objects/'];
    
    train_path_postfix = ['/', num2str(vobjectSize), '/train'];
    test_pathPostfix = ['/', num2str(vobjectSize), '/test'];
    
    addpath(genpath(pwd));
    
    if nargin < 3 % if true, will look for an autogenerated mat file with training results from previous run
        lazyMode = true;
    end
    if nargin < 2
        poseEstimateFlag = true;
    end
    if nargin < 1
        partialView = true;
    elseif strcmp(partialFlag, 'partial')
        partialView = true;
        method = 'top'; % feel free to change this, the other option is 'side'
        %method = 'side';
    elseif strcmp(partialFlag, 'full')
        partialView = false;
    else
        error('Unrecognized input argument.')
    end
    
    saveName = ['./Cache/auto_basis_size', num2str(vobjectSize), '_saved_Training_Data.mat'];
    prettyNames = strrep(regexprep(names,'(\<\w)','${upper($1)}'), '_', ' ');
    
    % load learned subspaces
    numClasses = numel(names);
    subspaces = cell(numClasses, 1);
    for i=1: numClasses
        subspaces{i} = load([pre, names{i}, post]);
    end
    
    % load test voxel objects
    trainVobjects = cell(numClasses, 1);
    testVobjects = cell(numClasses, 1);
    for i=1:numel(names)
        name = names{i};
        trainPath = [pathPrefix, name, train_path_postfix];
        testPath = [pathPrefix, name, test_pathPostfix];
        trainVobjects{i} = loadModelNetObjects(trainPath);
        testVobjects{i} = loadModelNetObjects(testPath);
        disp(['Loading ', name, ' class (' num2str(size(trainVobjects{i}, 4)), ' training objects and ',...
            num2str(size(testVobjects{i}, 4)) , ' test objects)']);
        
        MUs{i} = subspaces{i}.Mu; %#ok<AGROW>
        Ws{i} = subspaces{i}.A; %#ok<AGROW>
    end
    clear('subspaces'); % cleanup to save memory
    
    disp('Loading Complete')
    if partialView
        disp('Beginning experiment using partial views');
        viewStr = 'partial views'; %#ok<NASGU>
    else
        disp('Beginning experiment using full 3D object');
        viewStr = 'full 3D'; %#ok<NASGU>
    end
    
    
    % experiment proper
    
    % load pre-trained basis for each class (computed with VBPCA)
    % merge these into a single larger basis
    % fit multivariate normal distributions to each class using shrunk
    % covarience estimation
    %
    % if the lazymode setting is true, it will look for a previously saved
    % mat file with training results (containing the learned covariences, and
    % means as well as shared basis). If it can't find this file, or lazymode is false,
    % it will train from scratch
    disp('Beginning Training...');
    [sharedBasis, sharedMeans, sharedCovs] = train(MUs, Ws, trainVobjects, saveName, lazyMode);
    %sharedBasisGPU = gpuArray(sharedBasis);
    sharedBasisGPU = sharedBasis;
    disp('Training Complete');
    
    % loop over all test objects, store important stuff from experiments
    fineRotationError = [];
    corseEDTRotationError = [];
    trueRotations = {};
    fineEstimatedRotations = {};
    corseEDTEstimatedRotations = {};
    estimatedClass = [];
    fineReconstructionErrors = [];
    corseEDTReconstructionErrors = [];
    trueClass = [];
    corseEDTReconstructedObjects = {};
    fineReconstructedObjects = {};
    
    for testClass=1:numel(testVobjects)
        disp(['Beginning experiment for ', prettyNames{testClass} ' class']);
        classObjects = testVobjects{testClass};
        for testInstance=1:size(classObjects, 4)
            trueClass(end+1) = testClass; %#ok<AGROW>
            testObject = classObjects(:, :, :, testInstance);
            groundTruthTestObject = testObject;
            if partialView
                testObject = extractViewFromVoxel(testObject, method); % partial view mode, extract single view
            end
            % create random rotation about z axis
            if poseEstimateFlag
                R = compose_rotation_d(0, 0, rand()*360);
                
                % rotate the (possibly partial) object by the random rotation to create test
                % query
                [rotatedTestObject, ~] = rotateObject(testObject, affine3d(), R);
                rotatedTestObject = double(rotatedTestObject);
            else
                R = compose_rotation_d(0, 0, 0);
                rotatedTestObject = testObject;
            end
            trueRotations{end+1} = R; %#ok<AGROW>
            
            % jointly estimate pose, class, and 3D geometry
            [corseEDTEstimatedRotations{end+1}, fineEstimatedRotations{end+1}, estimatedClass(end+1),...
                corseEDTReconstructedObjects{end+1}, fineReconstructedObjects{end+1}]...
                = singleObjectRotClassifyComplete_1dof(rotatedTestObject, step, sharedMeans, sharedCovs, sharedBasisGPU, poseEstimateFlag); %#ok<AGROW>
            
            
            % LG: better visualization (for small test of test objects...
            disp('Press any key to show original/partial object');
            pause;
            visualizeObject(rotatedTestObject);
            
            disp('Press any key to show corseEDT reconstructed object');
            pause;
            visualizeObject(corseEDTReconstructedObjects{end});
            
            disp('Press any key to show fine reconstructed object');
            pause;
            visualizeObject(fineReconstructedObjects{end});
            
            % calculate pose estimation errors
            corseEDTDiff = rotm2axang(corseEDTEstimatedRotations{end} * trueRotations{end}'); % get distance between true rotation and estimate in radians
            corseEDTRotationError(end+1) = rad2deg(corseEDTDiff(4)); %#ok<AGROW> % convert to degrees
            fineDiff = rotm2axang(fineEstimatedRotations{end} * trueRotations{end}'); % get distance between true rotation and estimate in radians
            %fineDiff = rotm2axang(fineEstimatedRotations{end} *
            %trueRotations{end}); % this may be correct rotation
            fineRotationError(end+1) = rad2deg(fineDiff(4)); %#ok<AGROW> % convert to degrees
            
            % calculate reconstruction errors
            corseEDTReconstructionErrors(end+1) = interObjectDist(corseEDTReconstructedObjects{end}, groundTruthTestObject); %#ok<AGROW>
            fineReconstructionErrors(end+1) = interObjectDist(fineReconstructedObjects{end}, groundTruthTestObject); %#ok<AGROW>
        end
        classAcc = computeClassifierAccuracy(estimatedClass(trueClass == testClass), trueClass(trueClass == testClass), numel(names));
        disp(['Accuracy for ', prettyNames{testClass}, ' class: ', num2str(classAcc)]);
    end
    disp('Done');
    
    % end of experiment, plot results
    if poseEstimateFlag
        figure();
        hist(fineRotationError)
        title('Partial Object, Full Pipeline 1DOF')
        xlabel('Rotation Error (Degrees)')
        ylabel('Number of Occurences')
        
        figure();
        hist(corseEDTRotationError)
        title('Partial Object, 1DOF, EDT Error (corse)')
        xlabel('Rotation Error (Degrees)')
        ylabel('Number of Occurences')
    end
    figure();
    [acc, predMat, trueMat] = computeClassifierAccuracy(estimatedClass, trueClass, numel(names));
    displayClassifierResults('Full Pipeline_1dof', trueMat, predMat, acc, prettyNames, '');
    
    %save('fullPipeline_1dof_results.mat');
    
    % This bit of code (almost) plots completion errors in a pretty way. Unfortunatly, I broke it
    % somehow. In the meantime, completion information can be found in the
    % variable fineReconstructionErrors. Use hist for an easy plot.
    
    %f = figure();
    %s = nhist({fineReconstructionErrors},...
    %    'titles', {'Full Pipeline_1dof'}, 'xlabel', 'Completion Error', 'ylabel', 'Occurences', 'serror', 'text', 'color', 'sequential', 'fsize', 14);
    %axesHandles = get(f, 'children');
    %for i=1:numel(axesHandles)
    %    ylim(axesHandles(i), [0, 190])
    %    disp(linewrap(s{i}, 80));
    %end
end

function [sharedBasisReduced, sharedMeans, sharedCovs] = train(MUs, Ws, trainVobjects, saveName, lazyMode)
    if nargin < 4
        lazyMode = false;
        saveName = ['./Cache/autogenerated_saved_training_data)_', datestr(datetime('now'), 'mm-dd-yyyy_HH-MM')];
    elseif nargin < 5
        lazyMode = false;
    end
    saveFlag = false;
    if lazyMode && exist(saveName, 'file') ~= 2
        lazyMode = false;
        saveFlag = true;
    end
    
    % the line below computes the training dta
    if ~lazyMode
        sharedBasis = [];
        % add all prinComps from classes, also add class means
        for classNum=1:numel(Ws)
            sharedBasis(:, end+1:end+size(Ws{classNum}, 2)) = Ws{classNum};
            sharedBasis(:, end+1) = MUs{classNum}; %#ok<AGROW>
        end
        sharedBasisReduced = orth(sharedBasis);
        
        % find mean and cov for each class model on shared basis
        [sharedMeans, sharedCovs] = getSharedProjCovariencesAndMeans(sharedBasisReduced, trainVobjects);
        if saveFlag
            save(saveName);
        end
    else
        load(saveName);
        fprintf('Warning, lazy mode is enabled (loading precomputed trained models)\n\n');
    end
end

function [projMeans, projCovariences] = getSharedProjCovariencesAndMeans(W, trainVobjects)
    projCovariences = cell(numel(trainVobjects), 1);
    projMeans = cell(numel(trainVobjects), 1);
    for trainClass=1:numel(trainVobjects)
        classObjects = trainVobjects{trainClass};
        projectedObjs = zeros(size(classObjects, 4), size(W, 2));
        for trainInstance=1:size(classObjects, 4)
            object = classObjects(:, :, :, trainInstance);
            objectVector = reshape(object, numel(object), 1, 1);
            
            % project
            projectedObjs(trainInstance, :) = (W' * objectVector)';
        end
        projCovariences{trainClass} = cov2paraBen(projectedObjs, 1); % uses more memory, but higher quality estimate
        %projCovariences{trainClass} = cov(projectedObjs, 1);
        projMeans{trainClass} = mean(projectedObjs);
    end
end
